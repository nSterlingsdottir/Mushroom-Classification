# -*- coding: utf-8 -*-
"""Mushroom_Classification

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_LCZWx5sPuzXaC7-H6E-Ke-wdFQlBTJl
"""

import os
from google.colab import drive
drive.mount('/content/gdrive')
os.chdir('/content/gdrive/MyDrive/MA440')
!pwd 
!ls

#libraries

import pandas as pd
from pandas import read_csv
import statistics
import matplotlib.pyplot as plt
from sklearn.compose import make_column_transformer
from sklearn.preprocessing import OneHotEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import make_pipeline
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score,confusion_matrix
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn import metrics
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier,plot_tree
from sklearn.ensemble import RandomForestClassifier
import seaborn as sn
from sklearn.ensemble import AdaBoostClassifier
from sklearn.metrics import accuracy_score , plot_confusion_matrix , plot_roc_curve , plot_precision_recall_curve , classification_report

#Upload Data

#cleased_mushroom = read_csv('cleansed_mushroom2.csv')
#cleased_mushroom.head(9)

#x1 = cleased_mushroom.drop(['Unnamed: 0'], axis = 1)
#x1.head()

#x2 = x1.drop('class', axis = 1)
#x2.head()

#x2 = pd.get_dummies(x2, drop_first=True, prefix_sep='*')
#x2.head()

#y = x1['class']

#Using Cade's final processed data

cade_data = read_csv('final_processed_data_with_dummies.csv')
cade_data.head(9)

x1 = cade_data.drop(['Unnamed: 0'], axis = 1)
x1.head()

x1.shape

print(x1.describe())

x2 = x1.drop('class', axis = 1)
x2.head()

x2.shape

y = x1['class']

#X_train, X_test, y_train, y_test = train_test_split(x2, y, test_size=0.15, random_state=101)
X_train, X_test, y_train, y_test = train_test_split(x2, y, test_size=0.25, random_state=42)

#SVM

svs_model = SVC(C=10.0, kernel='rbf') #OG: C =1.0
svs_model.fit(X_train, y_train)

y_pred1 = svs_model.predict(X_test)
y_pred1

#print('Confusion matrix:')
#print(confusion_matrix(y_test,y_pred1))
print(classification_report(y_test, y_pred1))
plot_confusion_matrix(svs_model, X_test, y_test)
print('Accuracy for SVM:',accuracy_score(y_test,y_pred1))

from sklearn.metrics import cohen_kappa_score
cohen_score1 = cohen_kappa_score(y_test, y_pred1)
print("Kappa Score:", cohen_score1)

#SVM tune
from sklearn.model_selection import GridSearchCV

svs_clf = GridSearchCV(svs_model, {
    'C': [1, 10, 20],
    'kernel' : ['rbf', 'linear']
    }, cv=5, return_train_score=False, scoring = 'accuracy')

svs_clf.fit(X_train, y_train)
svs_clf.best_params_

#Logistic Regression

log_model = LogisticRegression(C= 25,penalty= 'l2')
log_model.fit(X_train, y_train)

y_pred = log_model.predict(X_test)
y_pred

#print('Confusion matrix:')
#print(confusion_matrix(y_test,y_pred))
print(classification_report(y_test, y_pred))
plot_confusion_matrix(log_model, X_test, y_test)
print('Accuracy for Log Reg:',accuracy_score(y_test,y_pred))

cohen_score2 = cohen_kappa_score(y_test, y_pred)
print("Kappa Score:", cohen_score2)

#Logistic reg tune
from sklearn.model_selection import GridSearchCV

param = {'penalty': ['l1', 'l2'],'C':[0.001,.009,0.01,.09,1,5,10,25]}
lr_clf = GridSearchCV(log_model,param, cv=5, return_train_score=False, scoring = 'accuracy')

lr_clf.fit(X_train, y_train)
lr_clf.best_params_

lr_clf.cv_results_
df = pd.DataFrame(lr_clf.cv_results_)
df[['param_C', 'param_penalty', 'mean_test_score']]

#KNN

dict1 = {'uniform':[],'distance':[]}
for i in dict1.keys():
    for k in range(1,21,2):
        clf = KNeighborsClassifier(n_neighbors = k,weights = i)
        clf.fit(X_train,y_train)
        y_predict = clf.predict(X_test)
        dict1[i].append(accuracy_score(y_test,y_predict))

dict2 = {'1':[],'2':[]}
for i in dict2.keys():
    for j in range(1,21,2):
        clf = KNeighborsClassifier(n_neighbors = j,weights = 'distance',p = int(i))
        clf.fit(X_train,y_train)
        y_pred2 = clf.predict(X_test)
        dict2[i].append(accuracy_score(y_test,y_pred2))

knn_model = KNeighborsClassifier(n_neighbors = j,weights = 'distance',p = int(i))
knn_model.fit(X_train,y_train)
y_pred2 = clf.predict(X_test)

#print('Confusion matrix:')
#print(confusion_matrix(y_test,y_pred2))
print(classification_report(y_test, y_pred2))
plot_confusion_matrix(knn_model, X_test, y_test)
print('Accuracy for KNN:',accuracy_score(y_test,y_pred2))

cohen_score3 = cohen_kappa_score(y_test, y_pred2)
print("Kappa Score:", cohen_score3)

#print(roc_auc)

#Decision Tree

cre = {'gini':[],'entropy':[]}
for i in cre.keys():
    for j in range(1,20):
        dec = DecisionTreeClassifier(criterion = i,max_depth = j)
        dec.fit(X_train,y_train)
        y_pred4 = dec.predict(X_test)
        cre[i].append(accuracy_score(y_test,y_pred4))

dec = DecisionTreeClassifier(criterion = 'entropy',max_depth = 6)
dec.fit(X_train,y_train)
y_pred4 = dec.predict(X_test)

plt.figure(figsize = [15,12])
q = plot_tree(dec,filled=True,feature_names = x2.columns,node_ids = True)

#print('Confusion matrix:')
#print(confusion_matrix(y_test,y_pred4))
print(classification_report(y_test, y_pred4))
plot_confusion_matrix(dec, X_test, y_test)
print('Accuracy for Decision Tree:',accuracy_score(y_test,y_pred4))

cohen_score4 = cohen_kappa_score(y_test, y_pred4)
print("Kappa Score:", cohen_score4)

import numpy as np
foldername = '/content/gdrive/MyDrive/MA440'
filename = foldername + '/cleansed_mushroom2.csv'
cleansed_mushroom = pd.read_csv(filename)

filename2 = foldername + '/preprocessed_mushroom_data.csv'
labels = pd.read_csv(filename2)

#poisonous = 1 
#edible = 0
labels = pd.DataFrame(labels['class'])
features = cleansed_mushroom.drop('class', axis = 1)
features = pd.get_dummies(data = features)

labels = np.array(labels)
features = np.array(features)

train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25, random_state = 42)

base_model = RandomForestClassifier(n_estimators = 1000, random_state = 42)
base_model.fit(train_features, train_labels)
base_predictions = base_model.predict(test_features)
#base_accuracy = model_accuracy(norm_predictions, test_labels)

# print('The accuracy of the base model is:', base_accuracy*100, '%')
# print('woo!')
confusionmat = confusion_matrix(test_labels,base_predictions)
print('Confusion matrix:')
print(confusion_matrix(test_labels,base_predictions))
print('Test accuracy for Decision Tree:',accuracy_score(test_labels,base_predictions)*100, '%')

from sklearn.metrics import accuracy_score , plot_confusion_matrix , plot_roc_curve , plot_precision_recall_curve , classification_report
print(classification_report(test_labels, base_predictions))
plot_confusion_matrix(base_model, test_features, test_labels)
print('Accuracy for Decision Tree:',accuracy_score(test_labels,base_predictions))

cohen_score5 = cohen_kappa_score(test_labels, base_predictions)
print("Kappa Score:", cohen_score5)

#Comparison

print('Accuracy for SVM:',accuracy_score(y_test,y_pred1))
print('Accuracy for Log Reg:',accuracy_score(y_test,y_pred))
print('Accuracy for KNN:',accuracy_score(y_test,y_pred2))
print('Accuracy for Decision Tree:',accuracy_score(y_test,y_pred4))
print('Accuracy for Random Forest:',accuracy_score(test_labels,base_predictions))

outcome = []
model_names = []
models = [('Log Reg', LogisticRegression()), 
          ('SVM', SVC()), 
          ('Decision Tree', DecisionTreeClassifier()),
          ('KNN', KNeighborsClassifier()), ('Random Forest',RandomForestClassifier()),('Adaboost',AdaBoostClassifier())]

from sklearn import model_selection

for model_name, model in models:
    k_fold_validation = model_selection.KFold(n_splits=10, random_state=None)
    results = model_selection.cross_val_score(model, x2, y, cv=k_fold_validation, scoring='accuracy')
    outcome.append(results)
    model_names.append(model_name)
    output_message = "%s| Mean=%f STD=%f" % (model_name, results.mean(), results.std())
    print(output_message)

print('Log Reg| Mean=0.890518 STD=0.109256\n')
print('SVM| Mean=0.919445 STD=0.102683\n')
print('Decision Tree| Mean=0.956580 STD=0.057386\n')
print('KNN| Mean=0.910114 STD=0.102032\n')
print('Random Forest| Mean=0.927306 STD=0.105067\n')
print('Adaboost| Mean=0.887154 STD=0.103752')

plt.rcParams["figure.figsize"] = (12,7)

fig = plt.figure()
plt.title('Algorithm Comparison')
ax = fig.add_subplot(111)
ax.boxplot(outcome)
ax.set_xticklabels(model_names)
plt.ylabel('Mean')
plt.xlabel('Algorithms')
plt.show()

print('Cohen''s Kappa score for SVM:',cohen_score1)
print('Cohen''s Kappa score for Log Reg:',cohen_score2)
print('Cohen''s Kappa score for KNN:',cohen_score3)
print('Cohen''s Kappa score for Decision Tree:',cohen_score4)
print('Cohen''s Kappa score for Random Forest:',cohen_score5)

ckvalues = [0.9861577181208053, 0.962248322147651, 0.9802852348993288,0.9425335570469798, 0.9937080536912751]
ckvalues2 = pd.DataFrame(data = ckvalues)
colmn1 = ['SVM','Log Reg','KNN','Decision Tree','Random Forest']
colmn2 = pd.DataFrame(data = colmn1)

togther = [colmn2, ckvalues]
togther

plt.subplots
sn.barplot(x = colmn1, y = ckvalues,palette='PuBuGn',edgecolor=sn.color_palette('dark',7))
plt.xticks(rotation=90)
plt.ylabel("Cohens Kappa Score")
plt.title('Cohens Kappa Score Comparison')
plt.show()

#SVM ROC and AUC
import sklearn
from sklearn import metrics

fpr, tpr, threshold = metrics.roc_curve(y_test, y_pred1)
roc_auc = metrics.auc(fpr, tpr)
plt.figure(1)
plt.plot([0, 1], [0, 1], 'k--')
plt.plot(fpr, tpr, label= 'AUC = {:.3f}'.format(roc_auc))
plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('SVM ROC curve')
plt.legend(loc='best')
plt.show()

#Logisitc Regression ROC and AUC
probs = log_model.predict_proba(X_test)
preds = probs[:,1]
fpr, tpr, threshold = metrics.roc_curve(y_test, preds)
roc_auc = metrics.auc(fpr, tpr)
plt.figure(1)
plt.plot([0, 1], [0, 1], 'k--')
plt.plot(fpr, tpr, label= 'AUC = {:.3f}'.format(roc_auc))
plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('Logistic Regression ROC curve')
plt.legend(loc='best')
plt.show()

#KNN ROC and AUC
probs = knn_model.predict_proba(X_test)
preds = probs[:,1]
fpr, tpr, threshold = metrics.roc_curve(y_test, preds)
roc_auc = metrics.auc(fpr, tpr)
plt.figure(1)
plt.plot([0, 1], [0, 1], 'k--')
plt.plot(fpr, tpr, label= 'AUC = {:.3f}'.format(roc_auc))
plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('KNN ROC curve')
plt.legend(loc='best')
plt.show()

#Decision Tree ROC and AUC
probs = dec.predict_proba(X_test)
preds = probs[:,1]
fpr, tpr, threshold = metrics.roc_curve(y_test, preds)
roc_auc = metrics.auc(fpr, tpr)
plt.figure(1)
plt.plot([0, 1], [0, 1], 'k--')
plt.plot(fpr, tpr, label= 'AUC = {:.3f}'.format(roc_auc))
plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('Decision Tree ROC curve')
plt.legend(loc='best')
plt.show()

#Random Forest ROC and AUC
probs = base_model.predict_proba(test_features)
preds = probs[:,1]
fpr, tpr, threshold = metrics.roc_curve(test_labels, preds)
roc_auc = metrics.auc(fpr, tpr)
plt.figure(1)
plt.plot([0, 1], [0, 1], 'k--')
plt.plot(fpr, tpr, label= 'AUC = {:.3f}'.format(roc_auc))
plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('Random Forest ROC curve')
plt.legend(loc='best')
plt.show()

x2.hist(figsize = (25, 25))
plt.show()

corr_mat = x2.corr()
corr_mat.style.background_gradient(cmap = 'Greens')